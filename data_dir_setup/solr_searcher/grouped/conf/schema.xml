<?xml version="1.0" ?>
<schema name="Pika Grouped Work Index" version="1.6">
	<!-- attribute "name" is the name of this schema and is only used for display purposes.
	   version="x.y" is Solr's version number for the schema syntax and
	   semantics.  It should not normally be changed by applications.

	   1.0: multiValued attribute did not exist, all fields are multiValued
			by nature
	   1.1: multiValued attribute introduced, false by default
	   1.2: omitTermFreqAndPositions attribute introduced, true by default
			except for text fields.
	   1.3: removed optional field compress feature
	   1.4: autoGeneratePhraseQueries attribute introduced to drive QueryParser
			behavior when a single string produces multiple tokens.  Defaults
			to off for version >= 1.4
	   1.5: omitNorms defaults to true for primitive field types
			(int, float, boolean, string...)
	   1.6: useDocValuesAsStored defaults to true.
	-->

	<types>
		<!-- Valid attributes for fields:
		 name: mandatory - the name for the field
		 type: mandatory - the name of a field type from the
		   fieldTypes section
		 indexed: true if this field should be indexed (searchable or sortable)
		 stored: true if this field should be retrievable
		 docValues: true if this field should have doc values. Doc Values is
		   recommended (required, if you are using *Point fields) for faceting,
		   grouping, sorting and function queries. Doc Values will make the index
		   faster to load, more NRT-friendly and more memory-efficient.
		   They are currently only supported by StrField, UUIDField, all
		   *PointFields, and depending on the field type, they might require
		   the field to be single-valued, be required or have a default value
		   (check the documentation of the field type you're interested in for
		   more information)
		 multiValued: true if this field may contain multiple values per document
		 omitNorms: (expert) set to true to omit the norms associated with
		   this field (this disables length normalization and index-time
		   boosting for the field, and saves some memory).  Only full-text
		   fields or fields that need an index-time boost need norms.
		   Norms are omitted for primitive (non-analyzed) types by default.
		 termVectors: [false] set to true to store the term vector for a
		   given field.
		   When using MoreLikeThis, fields used for similarity should be
		   stored for best performance.
		 termPositions: Store position information with the term vector.
		   This will increase storage costs.
		 termOffsets: Store offset information with the term vector. This
		   will increase storage costs.
		 required: The field is required.  It will throw an error if the
		   value does not exist
		 default: a value that should be used if no value is specified
		   when adding a document.
		-->

		<!-- field names should consist of alphanumeric or underscore characters only and
		  not start with a digit.  This is not currently strictly enforced,
		  but other field names will not have first class support from all components
		  and back compatibility is not guaranteed.  Names with both leading and
		  trailing underscores (e.g. _version_) are reserved.
		-->

		<fieldType name="string" class="solr.StrField" sortMissingLast="true" omitNorms="true" docValues="true"/>
		<fieldType name="integer" class="solr.IntPointField" omitNorms="true" docValues="true"/>
		<fieldType name="float" class="solr.FloatPointField" omitNorms="true" docValues="true"/>
		<fieldType name="long" class="solr.LongPointField" positionIncrementGap="0" docValues="true"/>
		<fieldType name="date" class="solr.DatePointField" docValues="true"/>
		<fieldType name="text" class="solr.TextField" positionIncrementGap="100">
			<analyzer type="index">
				<!-- Whitespace tokenizer is needed so the Word Delimiter filter factory works properly
				 For example, this allows E.T. The Extra-Terrestrial to be handled properly.  #ARL-168
				-->
				<tokenizer class="solr.WhitespaceTokenizerFactory"/>
				<!--
				Simple tokenizer that splits the text stream on whitespace and returns sequences of
				non-whitespace characters as tokens. Note that any punctuation will be included in the tokens.

				https://solr.apache.org/guide/8_8/tokenizers.html#white-space-tokenizer
				-->
				<filter class="solr.StopFilterFactory" ignoreCase="true" words="stopwords.txt"/>
				<!--
				This filter discards, or stops analysis of, tokens that are on the given stop words list.
				A standard stop words list is included in the Solr conf directory, named stopwords.txt,
				which is appropriate for typical English language text.

				https://solr.apache.org/guide/8_8/filter-descriptions.html#stop-filter
				-->
				<filter class="solr.ICUFoldingFilterFactory"/>
				<!--
				This filter is a custom Unicode normalization form that applies the foldings specified in Unicode TR #30: Character Foldings
				in addition to the NFKC_Casefold normalization form as described in ICU Normalizer 2 Filter.
				This filter is a better substitute for the combined behavior of the ASCII Folding Filter, Lower Case Filter,
				and ICU Normalizer 2 Filter.

				To use this filter, you must add additional .jars to Solr’s classpath
				See solr/contrib/analysis-extras/README.txt for instructions on which jars you need to add.

				From the README.txt: ICU relies upon lucene-libs/lucene-analyzers-icu-X.Y.jar and lib/icu4j-X.Y.jar

				https://solr.apache.org/guide/8_8/filter-descriptions.html#icu-folding-filter

				-->

				<filter class="solr.WordDelimiterGraphFilterFactory"
						generateWordParts="1"
						generateNumberParts="1"
						splitOnCaseChange="0"
						catenateAll="0"
						stemEnglishPossessive="1"

						preserveOriginal="1"
						catenateWords="0"
						catenateNumbers="0"
						splitOnNumerics="0"

						protected="protwords.txt"
				/>
				<!-- Turning off every option but stemEnglishPossessive for index analyzer for now.
				 Word Delimiter is needed to remove punctuation from tokens See D-4171 and D-4172

				  Turned on generateNumberParts, so that year phrases will get indexed like
				  uniform title: Pièces de clavecin (1729-1730)
				  author:  Jacquet de La Guerre, Elisabeth-Claude, 1665-1729
				  See D-4198

				// Turn off splitOnNumerics Pascal 7/19/21 tokenizes Ids like ".b1234x" into "b","1234,"x"   See D-3984

				// Turn on generateWordParts & preserveOriginal for index analyzer
				//so that phrases like trauma-informed can be matched with or without the dash
				// See IN-2955  Pascal 7/25/22
				-->
				<!--
				This filter splits tokens at word delimiters.
				If you use this filter during indexing, you must follow it with a Flatten Graph Filter to squash tokens on top of one another like the Word Delimiter Filter, because the indexer can’t directly consume a graph. To get fully correct positional queries when tokens are split, you should instead use this filter at query time.

				Note: although this filter produces correct token graphs, it cannot consume an input token graph correctly.

				The rules for determining delimiters are determined as follows:

					A change in case within a word: "CamelCase" -> "Camel", "Case". This can be disabled by setting splitOnCaseChange="0".

					A transition from alpha to numeric characters or vice versa: "Gonzo5000" -> "Gonzo", "5000" "4500XL" -> "4500", "XL". This can be disabled by setting splitOnNumerics="0".

					Non-alphanumeric characters (discarded): "hot-spot" -> "hot", "spot"

					A trailing "'s" is removed: "O’Reilly’s" -> "O", "Reilly"

					Any leading or trailing delimiters are discarded: "-hot-spot-" -> "hot", "spot" (original example uses double dashes not allowed in xml comments)


				From documentation : https://solr.apache.org/guide/8_8/filter-descriptions.html#word-delimiter-graph-filter

					generateWordParts
						(integer, default 1) If non-zero, splits words at delimiters. For example:"CamelCase", "hot-spot" -> "Camel", "Case", "hot", "spot"
					generateNumberParts
						(integer, default 1) If non-zero, splits numeric strings at delimiters:"1947-32" ->*"1947", "32"
					splitOnCaseChange
						(integer, default 1) If 0, words are not split on camel-case changes:"BugBlaster-XL" -> "BugBlaster", "XL". Example 1 below illustrates the default (non-zero) splitting behavior.
					splitOnNumerics
						(integer, default 1) If 0, don’t split words on transitions from alpha to numeric:"FemBot3000" -> "Fem", "Bot3000"
					catenateWords
						(integer, default 0) If non-zero, maximal runs of word parts will be joined: "hot-spot-sensor’s" -> "hotspotsensor"
					catenateNumbers
						(integer, default 0) If non-zero, maximal runs of number parts will be joined: 1947-32" -> "194732"
					catenateAll
						(0/1, default 0) If non-zero, runs of word and number parts will be joined: "Zap-Master-9000" -> "ZapMaster9000"
					preserveOriginal
						(integer, default 0) If non-zero, the original token is preserved: "Zap-Master-9000" -> "Zap-Master-9000", "Zap", "Master", "9000"
					protected
						(optional) The pathname of a file that contains a list of protected words that should be passed through without splitting.
					stemEnglishPossessive
						(integer, default 1) If 1, strips the possessive 's from each subword.
				-->
				<filter class="solr.FlattenGraphFilterFactory"/> <!-- required on index analyzers after graph filters -->
				<!--<filter class="solr.CommonGramsFilterFactory" words="stopwords.txt" ignoreCase="true"/>-->
				<!--The CommonGrams Filter is  prevented from going into effect here by the StopFilter above
				 TODO: in other words, I think the CommonGrams has to precede the StopFilter to have an effect
				 -->
				<filter class="solr.KeywordMarkerFilterFactory" protected="protwords.txt"/>
				<!--
				Protects words from being modified by stemmers. A customized protected word list may be specified with
				the "protected" attribute in the schema. Any words in the protected word list will not be modified
				by any stemmer in Solr.

				https://solr.apache.org/guide/8_8/language-analysis.html#keywordmarkerfilterfactory
				-->
				<filter class="solr.StemmerOverrideFilterFactory" dictionary="stemdict_en.txt" />
				<!-- Overrides stemming algorithms by applying a custom mapping, then protecting these terms from
				being modified by stemmers.

				A customized mapping of words to stems, in a tab-separated file, can be specified to the dictionary
				attribute in the schema. Words in this mapping will be stemmed to the stems from the file,
				and will not be further changed by any stemmer.

				https://solr.apache.org/guide/8_8/language-analysis.html#stemmeroverridefilterfactory
				-->
				<filter class="solr.SnowballPorterFilterFactory" protected="stemming_protect_en.txt" language="English"/>
				<!--This filter factory instantiates a language-specific stemmer generated by Snowball.
				Snowball is a software package that generates pattern-based word stemmers.
				This type of stemmer is not as accurate as a table-based stemmer, but is faster and less complex.
				Table-driven stemmers are labor intensive to create and maintain and so are typically commercial products.

				Solr contains Snowball stemmers for Armenian, Basque, Catalan, Danish, Dutch, English, Finnish, French,
				German, Hungarian, Italian, Norwegian, Portuguese, Romanian, Russian, Spanish, Swedish and Turkish.
				For more information on Snowball, visit https://snowballstem.org/

				 https://solr.apache.org/guide/8_8/filter-descriptions.html#snowball-porter-stemmer-filter

				 Note: The protected file prevents any stemming at all. If you want to specify how a word
				 should be stemmed instead, use StemmerOverrideFilterFactory above.
				 -->
				<filter class="solr.RemoveDuplicatesTokenFilterFactory"/>
			</analyzer>
			<analyzer type="query">
				<!--This filter uses regular expressions to replace or change character patterns.
				https://solr.apache.org/guide/8_8/charfilterfactories.html#solr-patternreplacecharfilterfactory
				-->
				<charFilter class="solr.PatternReplaceCharFilterFactory"
							pattern="(\w)\.(\w)\.(\w)\.?(?:\s|$)" replacement="$1 $2 $3 "/>
				<!--Replace 2 letter initials with out spaces between them with spaced initials
				w.e.b. du bois to w e b du bois
				w.e.b du bois to w e b du bois
				du bois, w.e.b to du bois, w e b
				du bois, w.e.b. to du bois, w e b
				   -->
				<charFilter class="solr.PatternReplaceCharFilterFactory"
							pattern="(\w)\.(\w)\.?(?:\s|$)" replacement="$1 $2 "/>
				<!--Replace 2 letter initials with out spaces between them with spaced initials
				 eg.  j.d robb to  j d robb
				  j.d. robb to j d robb
				  robb, j.d to robb, j d
				  robb, j.d. to robb, j d
				   -->
				<!--This filter uses regular expressions to replace or change character patterns.
				https://solr.apache.org/guide/8_8/charfilterfactories.html#solr-patternreplacecharfilterfactory

				-->
				<tokenizer class="solr.WhitespaceTokenizerFactory"/>
				<!-- Whitespace tokenizer is needed so the Word Delimiter filter factory works properly
				 For example, this allows E.T. The Extra-Terrestrial to be handled properly.  #ARL-168
				-->
				<!--
				Simple tokenizer that splits the text stream on whitespace and returns sequences of
				non-whitespace characters as tokens. Note that any punctuation will be included in the tokens.

				https://solr.apache.org/guide/8_8/tokenizers.html#white-space-tokenizer
				-->
				<filter class="solr.SynonymGraphFilterFactory" synonyms="synonyms.txt" ignoreCase="true" expand="true"/>
				<!-- Important: Only apply synonym filter to query analyzers; not to index analyzers-->
				<!-- Do our synonym filtering before word delimiter filters so that we don't create unwanted synonyms
				 	eg. 'wi-fi' => 'wi', 'fi' => 'wi', 'wisconsin', 'fi'
				 	See D-4066
				 -->
				<!-- https://solr.apache.org/guide/8_7/filter-descriptions.html#synonym-graph-filter
					If you use this filter during indexing, you must follow it with a Flatten Graph Filter to squash
					 tokens on top of one another like the Synonym Filter, because the indexer can’t directly consume
					 a graph. To get fully correct positional queries when your synonym replacements are multiple
					 tokens, you should instead apply synonyms using this filter at query time.

					Although this filter produces correct token graphs, it cannot consume an input token graph correctly.
				-->
				<filter class="solr.FlattenGraphFilterFactory"/> <!-- WordDelimiterGraphFilterFactory cannot consume SynonymGraphFilterFactory graphs -->
				<filter class="solr.WordDelimiterGraphFilterFactory"
						generateWordParts="1"
						generateNumberParts="1"
						splitOnCaseChange="1"
						catenateAll="0"
						stemEnglishPossessive="1"

						preserveOriginal="1"
						catenateWords="1"
						catenateNumbers="1"
						splitOnNumerics="0"

						protected="protwords.txt"
				/>
				<!-- Important: Only apply word delimiter graph filter to query analyzers; not to index analyzers-->
				<!--
				This filter splits tokens at word delimiters.
				If you use this filter during indexing, you must follow it with a Flatten Graph Filter to squash tokens on top of one another like the Word Delimiter Filter, because the indexer can’t directly consume a graph. To get fully correct positional queries when tokens are split, you should instead use this filter at query time.

				Note: although this filter produces correct token graphs, it cannot consume an input token graph correctly.

				The rules for determining delimiters are determined as follows:

					A change in case within a word: "CamelCase" -> "Camel", "Case". This can be disabled by setting splitOnCaseChange="0".

					A transition from alpha to numeric characters or vice versa: "Gonzo5000" -> "Gonzo", "5000" "4500XL" -> "4500", "XL". This can be disabled by setting splitOnNumerics="0".

					Non-alphanumeric characters (discarded): "hot-spot" -> "hot", "spot"

					A trailing "'s" is removed: "O’Reilly’s" -> "O", "Reilly"

					Any leading or trailing delimiters are discarded: "-hot-spot-" -> "hot", "spot" (original example uses double dashes not allowed in xml comments)


				https://solr.apache.org/guide/8_8/filter-descriptions.html#word-delimiter-graph-filter
				-->
				<!--
				// Turn off splitOnNumerics Pascal 7/19/21 tokenizes Ids like ".b1234x" into "b","1234,"x"   See D-3984

				// Turn preserveOriginal for query analyzer
				//so that phrases like trauma-informed can be matched with or without the dash
				// See IN-2955  Pascal 7/25/22

				From documentation : https://solr.apache.org/guide/8_8/filter-descriptions.html#word-delimiter-graph-filter

									generateWordParts
						(integer, default 1) If non-zero, splits words at delimiters. For example:"CamelCase", "hot-spot" -> "Camel", "Case", "hot", "spot"
					generateNumberParts
						(integer, default 1) If non-zero, splits numeric strings at delimiters:"1947-32" ->*"1947", "32"
					splitOnCaseChange
						(integer, default 1) If 0, words are not split on camel-case changes:"BugBlaster-XL" -> "BugBlaster", "XL". Example 1 below illustrates the default (non-zero) splitting behavior.
					splitOnNumerics
						(integer, default 1) If 0, don’t split words on transitions from alpha to numeric:"FemBot3000" -> "Fem", "Bot3000"
					catenateWords
						(integer, default 0) If non-zero, maximal runs of word parts will be joined: "hot-spot-sensor’s" -> "hotspotsensor"
					catenateNumbers
						(integer, default 0) If non-zero, maximal runs of number parts will be joined: 1947-32" -> "194732"
					catenateAll
						(0/1, default 0) If non-zero, runs of word and number parts will be joined: "Zap-Master-9000" -> "ZapMaster9000"
					preserveOriginal
						(integer, default 0) If non-zero, the original token is preserved: "Zap-Master-9000" -> "Zap-Master-9000", "Zap", "Master", "9000"
					protected
						(optional) The pathname of a file that contains a list of protected words that should be passed through without splitting.
					stemEnglishPossessive
						(integer, default 1) If 1, strips the possessive 's from each subword.
				-->
				<filter class="solr.FlattenGraphFilterFactory"/> <!-- required on index analyzers after graph filters -->
				<!--  TODO: Solr's managed schema examples do not have the flatten graph filter in its query analyzers -->
				<filter class="solr.StopFilterFactory" ignoreCase="true" words="stopwords.txt"/>
				<!--
				This filter discards, or stops analysis of, tokens that are on the given stop words list.
				A standard stop words list is included in the Solr conf directory, named stopwords.txt,
				which is appropriate for typical English language text.

				https://solr.apache.org/guide/8_8/filter-descriptions.html#stop-filter
				-->
				<filter class="solr.ICUFoldingFilterFactory"/>
				<!--
				This filter is a custom Unicode normalization form that applies the foldings specified in Unicode TR #30: Character Foldings
				in addition to the NFKC_Casefold normalization form as described in ICU Normalizer 2 Filter.
				This filter is a better substitute for the combined behavior of the ASCII Folding Filter, Lower Case Filter,
				and ICU Normalizer 2 Filter.

				To use this filter, you must add additional .jars to Solr’s classpath
				See solr/contrib/analysis-extras/README.txt for instructions on which jars you need to add.

				From the README.txt: ICU relies upon lucene-libs/lucene-analyzers-icu-X.Y.jar and lib/icu4j-X.Y.jar

				https://solr.apache.org/guide/8_8/filter-descriptions.html#icu-folding-filter

				-->
				<!--<filter class="solr.CommonGramsFilterFactory" words="stopwords.txt" ignoreCase="true"/>-->
				<!--The CommonGrams Filter is  prevented from going into effect here by the StopFiler above -->
				<filter class="solr.KeywordMarkerFilterFactory" protected="protwords.txt"/>
				<!--
				Protects words from being modified by stemmers. A customized protected word list may be specified with
				the "protected" attribute in the schema. Any words in the protected word list will not be modified
				by any stemmer in Solr.

				https://solr.apache.org/guide/8_8/language-analysis.html#keywordmarkerfilterfactory
				-->
				<filter class="solr.StemmerOverrideFilterFactory" dictionary="stemdict_en.txt" />
				<!-- Overrides stemming algorithms by applying a custom mapping, then protecting these terms from
				being modified by stemmers.

				A customized mapping of words to stems, in a tab-separated file, can be specified to the dictionary
				attribute in the schema. Words in this mapping will be stemmed to the stems from the file,
				and will not be further changed by any stemmer.

				https://solr.apache.org/guide/8_8/language-analysis.html#stemmeroverridefilterfactory
				-->
				<filter class="solr.SnowballPorterFilterFactory" protected="stemming_protect_en.txt" language="English"/>
				<!--This filter factory instantiates a language-specific stemmer generated by Snowball.
				Snowball is a software package that generates pattern-based word stemmers.
				This type of stemmer is not as accurate as a table-based stemmer, but is faster and less complex.
				Table-driven stemmers are labor intensive to create and maintain and so are typically commercial products.

				Solr contains Snowball stemmers for Armenian, Basque, Catalan, Danish, Dutch, English, Finnish, French,
				German, Hungarian, Italian, Norwegian, Portuguese, Romanian, Russian, Spanish, Swedish and Turkish.
				For more information on Snowball, visit https://snowballstem.org/

				 https://solr.apache.org/guide/8_8/filter-descriptions.html#snowball-porter-stemmer-filter

				 Note: The protected file prevents any stemming at all. If you want to specify how a word
				 should be stemmed instead, use StemmerOverrideFilterFactory above.
				 -->

				<filter class="solr.RemoveDuplicatesTokenFilterFactory"/>
			</analyzer>
		</fieldType>
		<fieldType name="text-proper" class="solr.TextField" positionIncrementGap="100">
			<analyzer>
				<tokenizer class="solr.ICUTokenizerFactory"/>
				<!--
				This tokenizer processes multilingual text and tokenizes it appropriately based on its script attribute.
				Requires additional jar files
				The default configuration for solr.ICUTokenizerFactory provides UAX#29 word break rules tokenization
				(like solr.StandardTokenizer), but also includes custom tailorings for Hebrew (specializing handling
				of double and single quotation marks), for syllable tokenization for Khmer, Lao, and Myanmar, and
				dictionary-based word segmentation for CJK characters.
				https://solr.apache.org/guide/8_8/tokenizers.html#icu-tokenizer
				-->
				<!--  Disabling using word delimiter graph on textProper till we prove it is needed. See D-4189
								<filter class="solr.WordDelimiterGraphFilterFactory"
										generateWordParts="1" generateNumberParts="1" catenateWords="1" catenateNumbers="1" catenateAll="0"
										splitOnCaseChange="1" splitOnNumerics="0" stemEnglishPossessive="1"
										protected="protected_en_contractions.txt"
								/>
								&lt;!&ndash; protect contractions for matching in text_proper See D-4189 &ndash;&gt;
								<filter class="solr.FlattenGraphFilterFactory"/> &lt;!&ndash; required on index analyzers after graph filters &ndash;&gt;
				-->
				<filter class="solr.ICUFoldingFilterFactory"/>
				<!--
				This filter is a custom Unicode normalization form that applies the foldings specified in Unicode TR #30: Character Foldings
				in addition to the NFKC_Casefold normalization form as described in ICU Normalizer 2 Filter.
				This filter is a better substitute for the combined behavior of the ASCII Folding Filter, Lower Case Filter,
				and ICU Normalizer 2 Filter.
				To use this filter, you must add additional .jars to Solr’s classpath
				See solr/contrib/analysis-extras/README.txt for instructions on which jars you need to add.
				From the README.txt: ICU relies upon lucene-libs/lucene-analyzers-icu-X.Y.jar and lib/icu4j-X.Y.jar
				https://solr.apache.org/guide/8_8/filter-descriptions.html#icu-folding-filter
				-->
			</analyzer>
		</fieldType>
		<!-- This is an example of using the KeywordTokenizer along
		 With various TokenFilterFactories to produce a sortable field
		 that does not include some properties of the source text
	  -->
		<fieldType name="alphaOnlySort" class="solr.TextField" sortMissingLast="true" omitNorms="true">
			<analyzer>
				<tokenizer class="solr.KeywordTokenizerFactory"/>
				<!-- KeywordTokenizer does no actual tokenizing, so the entire
					 input string is preserved as a single token

				 https://solr.apache.org/guide/8_8/tokenizers.html#keyword-tokenizer
				 -->
				<filter class="solr.LowerCaseFilterFactory"/>
				<!--
				Converts any uppercase letters in a token to the equivalent lowercase token. All other characters are left unchanged.

				https://solr.apache.org/guide/8_8/filter-descriptions.html#lower-case-filter
				-->
				<!-- The TrimFilter removes any leading or trailing whitespace -->
				<filter class="solr.TrimFilterFactory"/>
				<!-- The PatternReplaceFilter gives you the flexibility to use
				 Java Regular expression to replace any sequence of characters
				 matching a pattern with an arbitrary replacement string,
				 which may include back references to portions of the original
				 string matched by the pattern.

				 See the Java Regular Expression documentation for more
				 information on pattern and replacement string syntax.

				 http://java.sun.com/j2se/1.5.0/docs/api/java/util/regex/package-summary.html
				-->
				<filter class="solr.PatternReplaceFilterFactory" pattern="([^a-z0-9\s])" replacement="" replace="all"/>
				<!--This filter applies a regular expression to each token and, for those that match, substitutes the
				given replacement string in place of the matched pattern. Tokens which do not match are passed though unchanged.

				Note: This is different from the CharFilter solr.PatternReplaceCharFilterFactory

				https://solr.apache.org/guide/8_8/filter-descriptions.html#pattern-replace-filter
				-->
			</analyzer>
		</fieldType>
		<fieldType name="callnumber-search" class="solr.TextField" sortMissingLast="true" omitNorms="true">
			<analyzer type="index">
				<tokenizer class="solr.KeywordTokenizerFactory"/>
				<!-- KeywordTokenizer does no actual tokenizing, so the entire
					 input string is preserved as a single token

				 https://solr.apache.org/guide/8_8/tokenizers.html#keyword-tokenizer
				 -->
				<filter class="solr.LengthFilterFactory" min="2" max="100"/>
				<!-- This filter passes tokens whose length falls within the min/max limit specified.
				All other tokens are discarded.

				https://solr.apache.org/guide/8_8/filter-descriptions.html#length-filter
				-->
				<filter class="solr.LowerCaseFilterFactory"/>
				<!--
				Converts any uppercase letters in a token to the equivalent lowercase token. All other characters are left unchanged.

				https://solr.apache.org/guide/8_8/filter-descriptions.html#lower-case-filter
				-->
				<!-- The TrimFilter removes any leading or trailing whitespace -->
				<filter class="solr.TrimFilterFactory"/>
			</analyzer>
			<analyzer type="query">
				<tokenizer class="solr.KeywordTokenizerFactory"/>
				<!-- KeywordTokenizer does no actual tokenizing, so the entire
					 input string is preserved as a single token

				 https://solr.apache.org/guide/8_8/tokenizers.html#keyword-tokenizer
				 -->
				<filter class="solr.WordDelimiterGraphFilterFactory"
						generateWordParts="1"
						splitOnCaseChange="1"
						catenateAll="0"
						stemEnglishPossessive="0"

						catenateWords="1"
						catenateNumbers="1"
						splitOnNumerics="0"
						generateNumberParts="0"

				/>
				<!--TODO: should we apply any word delimiting to a call number search ? -->
				<!-- Important: Only apply word delimiter graph filter to query analyzers; not to index analyzers-->
				<!--
				// Turn off splitOnNumerics and generateNumberParts Pascal 7/19/21   Keep call number parts together

				From documentation : https://solr.apache.org/guide/8_8/filter-descriptions.html#word-delimiter-graph-filter

					generateWordParts
						(integer, default 1) If non-zero, splits words at delimiters. For example:"CamelCase", "hot-spot" -> "Camel", "Case", "hot", "spot"
					generateNumberParts
						(integer, default 1) If non-zero, splits numeric strings at delimiters:"1947-32" ->*"1947", "32"
					splitOnCaseChange
						(integer, default 1) If 0, words are not split on camel-case changes:"BugBlaster-XL" -> "BugBlaster", "XL". Example 1 below illustrates the default (non-zero) splitting behavior.
					splitOnNumerics
						(integer, default 1) If 0, don’t split words on transitions from alpha to numeric:"FemBot3000" -> "Fem", "Bot3000"
					catenateWords
						(integer, default 0) If non-zero, maximal runs of word parts will be joined: "hot-spot-sensor’s" -> "hotspotsensor"
					catenateNumbers
						(integer, default 0) If non-zero, maximal runs of number parts will be joined: 1947-32" -> "194732"
					catenateAll
						(0/1, default 0) If non-zero, runs of word and number parts will be joined: "Zap-Master-9000" -> "ZapMaster9000"
					preserveOriginal
						(integer, default 0) If non-zero, the original token is preserved: "Zap-Master-9000" -> "Zap-Master-9000", "Zap", "Master", "9000"
					protected
						(optional) The pathname of a file that contains a list of protected words that should be passed through without splitting.
					stemEnglishPossessive
						(integer, default 1) If 1, strips the possessive 's from each subword.
				-->
				<filter class="solr.FlattenGraphFilterFactory"/> <!-- required on index analyzers after graph filters -->
				<filter class="solr.LengthFilterFactory" min="2" max="100"/>
				<!-- This filter passes tokens whose length falls within the min/max limit specified.
				All other tokens are discarded.

				https://solr.apache.org/guide/8_8/filter-descriptions.html#length-filter
				-->
				<filter class="solr.LowerCaseFilterFactory"/>
				<!--TODO: shouldn't we apply this immediately after the tokenizer ? -->
				<!--
				Converts any uppercase letters in a token to the equivalent lowercase token. All other characters are left unchanged.

				https://solr.apache.org/guide/8_8/filter-descriptions.html#lower-case-filter
				-->
				<!-- The TrimFilter removes any leading or trailing whitespace -->
				<filter class="solr.TrimFilterFactory"/>
			</analyzer>
		</fieldType>
		<fieldType name="text-exact" class="solr.TextField" sortMissingLast="true" omitNorms="true">
			<!--TODO: explain why this special handling is needed for these fields instead of just using a regular solr string field;
			 OR TODO: replace with solr string field
			  unquoted search phrases of these fields with multiple words bring in totally unwanted results. pascal 10/25/2021
			-->
			<analyzer>
				<charFilter class="solr.PatternReplaceCharFilterFactory" pattern="^\s*(.*)\s*$" replacement="aaaa $1 zzzz"/>
				<!-- KeywordTokenizer does no actual tokenizing, so the entire input string is preserved as a single token

				 https://solr.apache.org/guide/8_8/tokenizers.html#keyword-tokenizer
				 -->
				<tokenizer class="solr.KeywordTokenizerFactory"/>
				<!-- KeywordTokenizer does no actual tokenizing, so the entire
					 input string is preserved as a single token

				 https://solr.apache.org/guide/8_8/tokenizers.html#keyword-tokenizer
				 -->
				<filter class="solr.LowerCaseFilterFactory"/>
				<!--
				Converts any uppercase letters in a token to the equivalent lowercase token. All other characters are left unchanged.

				https://solr.apache.org/guide/8_8/filter-descriptions.html#lower-case-filter
				-->
			</analyzer>
		</fieldType>
		<fieldType name="text-left" class="solr.TextField" sortMissingLast="true" omitNorms="true">
			<analyzer type="index">
				<charFilter class="solr.PatternReplaceCharFilterFactory" pattern="^\s*(.*)\s*$" replacement="aaaa $1"/>
				<!--This filter uses regular expressions to replace or change character patterns.
				https://solr.apache.org/guide/8_8/charfilterfactories.html#solr-patternreplacecharfilterfactory
				-->
				<tokenizer class="solr.KeywordTokenizerFactory"/>
				<!-- KeywordTokenizer does no actual tokenizing, so the entire
					 input string is preserved as a single token

				 https://solr.apache.org/guide/8_8/tokenizers.html#keyword-tokenizer
				 -->
				<filter class="solr.LowerCaseFilterFactory"/>
				<!--
				Converts any uppercase letters in a token to the equivalent lowercase token. All other characters are left unchanged.

				https://solr.apache.org/guide/8_8/filter-descriptions.html#lower-case-filter
				-->
				<!-- The TrimFilter removes any leading or trailing whitespace -->
				<filter class="solr.TrimFilterFactory"/>
				<filter class="solr.EdgeNGramFilterFactory" minGramSize="5" maxGramSize="40"/>
				<!-- This filter generates edge n-gram tokens of sizes within the given range.
				https://solr.apache.org/guide/8_8/filter-descriptions.html#edge-n-gram-filter

				Note: phrases can only be up to 35 characters long to have a match against the n-grams here.
				(5 characters from "aaaa " + max of 35 = maxGramSize (40))
				-->
				<filter class="solr.RemoveDuplicatesTokenFilterFactory"/>
			</analyzer>
			<analyzer type="query">
				<charFilter class="solr.PatternReplaceCharFilterFactory" pattern="^\s*(.*)\s*$" replacement="aaaa $1"/>
				<!--This filter uses regular expressions to replace or change character patterns.
				https://solr.apache.org/guide/8_8/charfilterfactories.html#solr-patternreplacecharfilterfactory
				-->
				<tokenizer class="solr.KeywordTokenizerFactory"/>
				<!-- KeywordTokenizer does no actual tokenizing, so the entire
					 input string is preserved as a single token

				 https://solr.apache.org/guide/8_8/tokenizers.html#keyword-tokenizer
				 -->
				<filter class="solr.LowerCaseFilterFactory"/>
				<!--
				Converts any uppercase letters in a token to the equivalent lowercase token. All other characters are left unchanged.

				https://solr.apache.org/guide/8_8/filter-descriptions.html#lower-case-filter
				-->
			</analyzer>
		</fieldType>
		<fieldType name="random" class="solr.RandomSortField"/>
	</types>
	<fields>
		<field name="_version_" type="long" indexed="false" stored="false"/>
		<!-- docValues are enabled by default for long type so we don't need to index the version field  -->

		<!-- Main Id -->
		<!-- 	The solr documents id is based on the grouped work id, except for user list documents -->
		<field name="id" type="string" indexed="true" stored="true" omitNorms="true"/>
		<field name="recordtype" type="string" indexed="true" stored="true" multiValued="false" omitNorms="false"/>
		<field name="alternate_ids" type="string" indexed="true" stored="false" multiValued="true" omitNorms="true"/>
		<field name="last_indexed" type="date" indexed="false" stored="true" multiValued="false"/>
		<!-- Now automatically set by solr_master core. (So the schema definition is slightly different -->

		<!-- Related Record information -->
		<field name="scope_has_related_records" type="string" indexed="true" stored="true" multiValued="true" docValues="true"/>
		<!-- Allows us to filter out works that are not part of the end user's search scope.  -->
		<field name="record_details" type="string" indexed="false" stored="true" multiValued="true"/>
		<field name="item_details" type="string" indexed="false" stored="true" multiValued="true"/>
		<dynamicField name="scoping_details_*" type="string" indexed="false" stored="true" multiValued="true"/>

		<!-- Fields to determine ownership and location based on location codes -->
		<dynamicField name="owning_library_*" type="string" indexed="true" stored="true" multiValued="true" omitNorms="false" docValues="true"/>
		<dynamicField name="owning_location_*" type="string" indexed="true" stored="true" multiValued="true" omitNorms="false" docValues="true"/>
		<dynamicField name="detailed_location_*" type="string" indexed="true" stored="true" multiValued="true" omitNorms="true" docValues="true"/>

		<dynamicField name="collection_*" type="string" indexed="true" stored="true" multiValued="true" omitNorms="false" docValues="true"/>

		<!-- Fields to determine availability -->
		<dynamicField name="available_at_*" type="string" indexed="true" stored="true" multiValued="true" omitNorms="true" docValues="true"/>
		<dynamicField name="availability_toggle_*" type="string" indexed="true" stored="true" multiValued="true" omitNorms="true" docValues="true"/>
		<!-- Link availability and format for better FRBR display -->
		<dynamicField name="availability_by_format_*" type="string" indexed="true" stored="true" multiValued="true" omitNorms="true"/>

		<!-- Title variations -->
		<field name="title" type="text" indexed="true" stored="true"/>  <!-- basic title -->
		<field name="title_exact" type="text-exact" indexed="true" stored="true"/>  <!-- basic title -->
		<field name="title_left" type="text-left" indexed="true" stored="true"/>  <!-- basic title -->
		<field name="title_proper" type="text-proper" indexed="true" stored="false"/>  <!-- basic title -->
		<field name="title_display" type="text" indexed="true" stored="true" multiValued="false"/> <!-- The title to display to the user -->
		<field name="title_sort" type="alphaOnlySort" indexed="true" stored="true"/> <!-- title for sorting -->
		<field name="title_sub" type="text" indexed="true" stored="true"/>
		<field name="title_short" type="text" indexed="true" stored="true"/>
		<field name="title_full" type="text" indexed="true" stored="true" multiValued="true"/> <!-- Title full includes the author -->
		<!--All 245 subfields separated by a space.  If a 245c (author in title) isn't present, the author found
		  in the 100abcdq or 110ab is added to the end of the title fields.
		  Note: This is important for search strategies the combine a title phrase with an author phrase, especially
		  sparsely populated marc. (like order records with may only have 245 & 100 tags populated.
		  -->
		<field name="title_alt" type="text" indexed="true" stored="true" multiValued="true"/>
		<!-- Alternate Titles
		130adfgklnpst:240a:246abnp:700tnr:730adfgklnpst:740a

		MARC 130 Tag    Uniform Title

		https://www.loc.gov/marc/bibliographic/bd130.html

		Uniform title used as a main entry in a bibliographic record. Main entry under a uniform title is used
		when a work is entered directly under title and the work has appeared under varying titles, necessitating that
		a particular title be chosen to represent the work. Cataloging rules also prescribe the use of this field when
		the work is entered directly under title and additions or deletions to the title proper must be accommodated.
		In this latter case, the title may not actually vary from iteration to iteration.

		The title that appears on the work being cataloged is contained in field 245.
		There will be no 100, 110, or 111 field in records with field 130.

		Subfields that are included to be indexed are :
		$a - Uniform title (NR)
		$d - Date of treaty signing (R)
		$f - Date of a work (NR)
		$g - Miscellaneous information (R)
		$k - Form subheading (R)
		$l - Language of a work (NR)
		$n - Number of part/section of a work (R)
		$p - Name of part/section of a work (R)
		$s - Version (R)
		$t - Title of a work (NR)



		MARC 240 Tag     Uniform Title

		https://www.loc.gov/marc/bibliographic/bd240.html

		Uniform title for an item when the bibliographic description is entered under a main entry field that contains
		a personal (field 100), corporate (110), or meeting (111) name.

		Used when a work has appeared under varying titles, necessitating that a particular title be chosen to
		represent the work. Cataloging rules also prescribe the use of this field when additions or deletions to the
		title must be accommodated. In the latter case, the title may not actually vary from iteration to iteration.

		The title that appears on the work being cataloged is contained in field 245 (Title Statement). Field 240 is
		not used when field 130 (Main Entry-Uniform Title) is present.

		Subfields that are included to be indexed are :
		$a - Uniform title (NR)



		MARC 246 Tag     Varying Form of Title (R)

		https://www.loc.gov/marc/bibliographic/bd246.html


		Varying forms of the title appearing on different parts of an item or a portion of the title proper, or an
		alternative form of the title when the form differs substantially from the title statement in field 245 and
		if they contribute to the further identification of the item.

		For items including several works but lacking a collective title, field 246 is used only for titles related to
		the title selected as the title proper, usually the first work named in the chief source of information.
		Titles related to other works are recorded in field 740 (Added Entry-Uncontrolled Related/Analytical Title)
		or one of the other 7XX (Added Entry) fields.

		When displayed/printed as a note, varying forms of titles are usually preceded by an introductory term or
		phrase that is generated as a display constant based on the second indicator value.

		Subfields that are included to be indexed are :
		$a - Title proper/short title (NR)
		$b - Remainder of title (NR)
		$n - Number of part/section of a work (R)
		$p - Name of part/section of a work (R)

		700tnr

		730adfgklnpst

		740a
		-->

		<!--Removing title_old and title_new for now, until we create a use. Pascal 7/20/2021 -->
<!--		<field name="title_old" type="text" indexed="true" stored="true" multiValued="true"/>-->
		<!--MARC 780 tag Preceding Entry
		$a - Main entry heading (NR)
		$s - Uniform title (NR)
		$t - Title (NR)

		Looks to be the previous title in a series
		-->
<!--		<field name="title_new" type="text" indexed="true" stored="true" multiValued="true"/>-->
		<!--MARC 785 tag Succeeding Entry
		$a - Main entry heading (NR)
		$s - Uniform title (NR)
		$t - Title (NR)

		Looks to be the next title in a series
		 -->
		<!-- Author variations -->
		<field name="author" type="text" indexed="true" stored="true" />
		<!-- MARC tag 100abcdq or 110ab
		Most common value from related records with format Book is used; if there is no related record with format Book,
		the most common value from related records with format eBook is used; if there neither Book nor eBook, the most common
		value is used.

		In cases of equally common values, the longer value is used.
		(under presumption that longer version will likely contain birth year - death year phrase)
		 -->
		<field name="authorStr" type="string" indexed="true" stored="true" docValues="true"/>
		<!-- authorStr is used an author facet.  It is copy field that uses author above as its source. -->
		<!-- TODO: ? reverse the pattern here. populate the simple string field (authorStr) and make author field
		above the  copy field? -->
		<field name="author_exact" type="text-exact" indexed="true" stored="true" />
		<!-- copy field with author as source -->
		<!-- Note: in order to match against this field, the search query must include punctuation for the surname style
		eg To match "Last, First" the search query must-"last, first".  "last first" will not match -->

		<field name="author_left" type="text-left" indexed="true" stored="true" />
		<!-- copy field with author as source -->

		<field name="author_display" type="string" indexed="true" stored="true" multiValued="false"/>
		<!-- The title to display to the user -->
		<!--trimmed 100a or 110ab -->
		<field name="auth_author" type="text-proper" indexed="true" stored="false"/>
		<!-- First MARC 100 - Main Entry-Personal Name
			$a - Personal name (NR)
			$b - Numeration (NR)
			$c - Titles and words associated with a name (R)
			$d - Dates associated with a name (NR)
		-->
<!--		<field name="auth_authorStr" type="string" indexed="true" stored="false"/>-->
		<field name="author2" type="text" indexed="true" stored="true" multiValued="true"/>
		<!-- All MARC tags 110ab, 111ab, 700abcd, 710ab, 711ab, and 800a -->
<!--		<field name="author2Str" type="string" indexed="true" stored="true" multiValued="true"/>-->
		<field name="author2-role" type="string" indexed="true" stored="true" multiValued="true"/>
		<!-- The contributor with role and title appended -->
		<!-- All MARC tags 700abcdetmnr and 710abcdetmnr with translation of relator code (subfield 4) appended after pipe character "|" -->
		<field name="auth_author2" type="text-proper" indexed="true" stored="true" multiValued="true"/>
		<!--TODO: stored needed for auth_author2 -->
		<!-- All MARC tags 700abcd -->
<!--		<field name="auth_author2Str" type="string" indexed="true" stored="false" multiValued="true"/>-->
		<field name="author_additional" type="text" indexed="true" stored="true" multiValued="true"/>
		<!-- All MARC tags 505r and 245c -->
<!--		<field name="author_additionalStr" type="string" indexed="true" stored="false" multiValued="true"/> Pretty sure this is redundant pascal. 7/19/21 -->

		<!-- format -->
		<field name="grouping_category" type="string" indexed="true" stored="true" multiValued="false" omitNorms="true"/>
		<!--TODO: Is there a reason to index the grouping_category ? -->
		<!--TODO: Is there a reason to have this stored -->
		<dynamicField name="format_*" type="string" indexed="true" stored="true" multiValued="true" omitNorms="true" docValues="true"/>
		<dynamicField name="format_boost_*" type="integer" indexed="false" stored="true" multiValued="false" omitNorms="true"/>
		<dynamicField name="format_category_*" type="string" indexed="true" stored="true" multiValued="true" omitNorms="true" docValues="true"/>

		<!-- Publication information -->
		<field name="publisher" type="text-proper" indexed="true" stored="true" multiValued="true"/>
		<field name="publishDate" type="string" indexed="true" stored="true" multiValued="true" docValues="true"/>
		<field name="publishDateSort" type="string" indexed="true" stored="true"/>
		<!--The earliest publication date on the grouped work -->
		<!--TODO: Is there a reason to have this stored -->
		<field name="edition" type="string" indexed="true" stored="true" multiValued="true"/>
		<!--		<field name="dateSpan" type="string" indexed="true" stored="true" multiValued="true"/>-->
		<!--field for MARC 362a Dates of Publication and/or Sequential Designation  -->
		<!--The MARC 361a data doesn't seem to have a format that would be easily parsable.
		  There is nothing in the front end that uses it from solr or directly from the MARC.
		  Nothing searches against the field, and I can't think of how it would be useful for a search
		  -->

		<!-- Physical Descriptions -->
		<field name="physical" type="string" indexed="false" stored="true" multiValued="true"/>
		<!-- 300abcefg:530abcd -->
		<!-- Stored but not indexed. There is no searching against this field, but the grouped work driver does
		use the solr field to populate the Main Details entry Physical Description (summPhysicalDesc) -->

		<!-- Things for faceting and refined searching -->

		<!-- series -->
		<field name="series" type="text" indexed="true" stored="true" multiValued="true"/>
		<!--
			Novelist Series Information

			or if no novelist, then MARC data :

			MARC tag 830 - Series Added Entry-Uniform Title
			a - Uniform title
			p - Name of part/section of a work

			 https://www.loc.gov/marc/bibliographic/bd830.html

			MARC tag 800 - Series Added Entry-Personal Name
			p - Name of part/section of a work
			q - Fuller form of name
			t - Title of a work

			https://www.loc.gov/marc/bibliographic/bd800.html
		-->
		<field name="series_proper" type="text-proper" indexed="true" stored="false" multiValued="true"/>
		<field name="series_with_volume" type="string" indexed="false" stored="true" multiValued="true"/>
		<!-- Not indexed, used for display only. Takes any entry in series and appends series volume number after a pipe | character

		 Novelist Series Information
		 or if no novelist, then MARC data as from series above; combined with subfield
		 v - Volume/sequential designation
		 -->
		<field name="series2" type="text" indexed="true" stored="true" multiValued="true"/>
		<!--TODO: is series2 really needed?? -->
		<!--
			MARC tag490 - Series Statement
			a - Personal name

			https://www.loc.gov/marc/bibliographic/bd490.html
		-->

		<!-- subject facets-->
		<field name="subject_facet" type="string" indexed="true" stored="true" multiValued="true" docValues="true"/>
		<field name="subject" type="text" indexed="true" stored="true" multiValued="true"/>
		<field name="subject_proper" type="text-proper" indexed="true" stored="false" multiValued="true"/>
		<field name="topic" type="text" indexed="true" stored="true" multiValued="true"/>
		<field name="topic_proper" type="text-proper" indexed="true" stored="false" multiValued="true"/>
		<field name="topic_facet" type="string" indexed="true" stored="true" multiValued="true" docValues="true"/>
		<field name="lc_subject" type="string" indexed="true" stored="true" multiValued="true" docValues="true"/>
		<field name="bisac_subject" type="string" indexed="true" stored="true" multiValued="true" docValues="true"/>
		<field name="genre" type="text" indexed="true" stored="true" multiValued="true"/>
		<field name="genre_proper" type="text-proper" indexed="true" stored="false" multiValued="true"/>
		<field name="genre_facet" type="string" indexed="true" stored="true" multiValued="true" docValues="true"/>
		<field name="geographic" type="text" indexed="true" stored="true" multiValued="true"/>
		<field name="geographic_proper" type="text-proper" indexed="true" stored="false" multiValued="true"/>
		<field name="geographic_facet" type="string" indexed="true" stored="true" multiValued="true" docValues="true"/>
		<field name="era" type="string" indexed="true" stored="true" multiValued="true" docValues="true"/>
		<field name="era_proper" type="text-proper" indexed="true" stored="false" multiValued="true"/>

		<field name="literary_form_full" type="string" indexed="true" stored="true" multiValued="true" docValues="true"/>
		<!-- Detailed version of the literary form. Typically consists of values: Non Fiction, Fiction, Dramas,
			Essays, Novels, Humor, Satires, etc., Letters, Short Stories, Mixed Forms, Poetry, Speeches, Unknown,
			Not Coded-->
		<field name="literary_form" type="string" indexed="true" stored="true" multiValued="true" docValues="true"/>
		<!--simple version of literary form. Consists of values: Fiction, Non Fiction, Unknown, Not Coded -->

		<!-- audience -->
		<field name="target_audience_full" type="string" indexed="true" stored="true" multiValued="true" docValues="true"/>
		<field name="target_audience" type="string" indexed="true" stored="true" multiValued="true" docValues="true"/>

		<!-- when added to the catalog -->
		<field name="date_added" type="date" indexed="true" stored="true" multiValued="false"/>
		<field name="time_since_added" type="string" indexed="true" stored="true" multiValued="true" docValues="true"/>
		<field name="days_since_added" type="integer" indexed="true" stored="true" multiValued="false"/>
		<dynamicField name="local_time_since_added_*" type="string" indexed="true" stored="true" multiValued="true"/>
		<dynamicField name="local_days_since_added_*" type="integer" indexed="true" stored="true" multiValued="false"/>

		<dynamicField name="itype_*" type="string" indexed="true" stored="true" multiValued="true" docValues="true"/>
		<field name="barcode" type="string" indexed="true" stored="false" multiValued="true"/>

		<!-- awards and ratings -->
		<field name="mpaa_rating" type="string" indexed="true" stored="true" multiValued="true" docValues="true"/>
		<field name="awards_facet" type="string" indexed="true" stored="true" multiValued="true" docValues="true"/>

		<!--Reading level data -->
		<field name="lexile_score" type="integer" indexed="true" stored="true" multiValued="false" default="-1" docValues="true"/>
		<field name="lexile_code" type="string" indexed="true" stored="true" multiValued="false" docValues="true"/>
		<field name="fountas_pinnell" type="string" indexed="true" stored="true" multiValued="false" docValues="true"/>
		<field name="accelerated_reader_interest_level" type="string" indexed="true" stored="true" multiValued="false" docValues="true"/>
		<field name="accelerated_reader_reading_level" type="float" indexed="true" stored="true" multiValued="false" default="0" docValues="true"/>
		<field name="accelerated_reader_point_value" type="float" indexed="true" stored="true" multiValued="false" default="0" docValues="true"/>

		<!-- eContent related fields -->
		<field name="econtent_device" type="string" indexed="true" stored="true" multiValued="true" docValues="true"/>
			<!--TODO: remove-->
		<dynamicField name="econtent_source_*" type="string" indexed="true" stored="true" multiValued="true" docValues="true"/>

		<!-- Broad Search Terms -->
		<field name="table_of_contents" type="text" indexed="true" stored="true" multiValued="true"/>
		<field name="table_of_contents_proper" type="text-proper" indexed="true" stored="true" multiValued="true"/>
		<!-- Only used in searchspec KeywordProper TODO: keep?; turn off stored? -->
		<field name="keywords" type="text" indexed="true" stored="false"/>
		<field name="keywords_proper" type="text-proper" indexed="true" stored="false"/>
		<field name="description" type="text" indexed="true" stored="false"/>
		<!-- all MARC 520a tags from all related records and OverDrive metadata shortDescription & fullDescription -->
		<field name="display_description" type="string" indexed="false" stored="true"/>
		<!--The "best" description to present to users. This is intended to be the description shown in search results.
		 Indexing prefers description based on format: book over ebook, then ebook over other formats.
		 Within the preferred format, the longest description is used.-->

		<!-- Identifiers -->
<!--		<field name="lccn" type="string" indexed="true" stored="true" multiValued="true"/>-->
		<field name="oclc" type="string" indexed="true" stored="true" multiValued="true"/>
		<!-- All MARC tags 035a
		 $a - System control number - MARC code (enclosed in parentheses) of the organization originating the system control number, followed immediately by the number.
		 -->
		<!-- oclc field is only searched directly with Pika Keyword Proper searchspec.
		oclc numbers also get added to catch-all keyword field.
		-->

		<!--
		primary_isbn, isbn, issn, primary_upc, & upc were all type="text-proper".
		Switch to regular "string". I don't think any of these fields need any special analyzer or index handling
		pascal 7/27/2021
		-->
		<field name="isbn" type="string" indexed="true" stored="true" multiValued="true"/>
		<field name="canceled_isbn" type="string" indexed="true" stored="true" multiValued="true"/>
		<!--MARC 020z Canceled/invalid ISBN
		Often Used by Academic libraries to compare eContent records  See D-2534
		 -->
		<field name="issn" type="string" indexed="true" stored="true" multiValued="true"/>
		<field name="upc" type="string" indexed="true" stored="true" multiValued="true"/>
		<field name="primary_isbn" type="string" indexed="false" stored="true" multiValued="false"/>
		<field name="primary_upc" type="string" indexed="false" stored="true" multiValued="false"/>

		<!-- Call Numbers -->
		<field name="callnumber-first" type="string" indexed="true" stored="true" docValues="true"/>
		<!-- callnumber-first is populated by translations of the first letter of a Library of Congress style call number.
		099a for a locally assigned free text call number, or then a 090a for locally assigned LC style call numbers,
		or then 050a for the Library of Congress Call Number.
		So TP245.T9, translates "T" to "T - Technology".  This field uses the translation file
		callnumber_map.properties
		 Currently this field only contributes to the KeywordProper search -->

		<field name="callnumber-subject" type="string" indexed="true" stored="true"/>
		<!-- callnumber-subject is populated by translations of the first two letters of a Library of Congress style call number.
		090a for locally assigned LC style call numbers or 050a for the Library of Congress Call Number
		So TP245.T9, translates "TP" to "TP - Chemical Technology".  This field uses the translation file
		callnumber_subject_map.properties
		 Currently this field only contributes to the KeywordProper search -->
		<dynamicField name="local_callnumber_*" type="callnumber-search" indexed="true" stored="true" multiValued="true"/>
		<dynamicField name="local_callnumber_exact_*" type="text-exact" indexed="true" stored="true" multiValued="true"/>
		<dynamicField name="local_callnumber_left_*" type="text-left" indexed="true" stored="true" multiValued="true"/>
		<dynamicField name="callnumber_sort_*" type="text-exact" indexed="true" stored="true" multiValued="false"/>

		<!-- Language Related Fields -->
		<dynamicField name="language_*" type="string" indexed="true" stored="true" multiValued="true" omitNorms="true" docValues="true"/>
		<dynamicField name="translation_*" type="string" indexed="true" stored="true" multiValued="true" omitNorms="true" docValues="true"/>

		<!-- Fields for boosting branch holdings -->
		<dynamicField name="lib_boost_*" type="integer" indexed="false" stored="true" multiValued="false" omitNorms="true"/>
		<!-- If the scope as an item available, the scope will get the availableAtLocationBoostValue.
			If the scope owns an item but none are available, the scope will get the ownedByLocationBoostValue.
		usual default values set in searches.ini :
				availableAtLocationBoostValue = 50
				ownedByLocationBoostValue = 10
		-->
		<!-- relevance determiners -->
		<field name="popularity" type="integer" indexed="true" stored="true" multiValued="false" default="0"/>

		<!-- Fields from Pika Enrichment -->
		<field name="tag" type="string" indexed="true" stored="true" multiValued="true"/>
		<!--TODO: nothing is indexed into this field "tag"-->
		<field name="rating" type="float" indexed="true" stored="true" multiValued="false" default="2.5"/>
		<field name="rating_facet" type="string" indexed="true" stored="true" multiValued="true" docValues="true"/>
		<field name="system_list" type="string" indexed="true" stored="true" multiValued="true"/>
		<!-- Wake County's (Horizon's?) unique feature system list populated from MARC 449a
		 to create a System List facet. -->

		<!-- Special fields for Lists -->
		<field name="num_titles" type="integer" indexed="true" stored="true" multiValued="false"/>
		<!--It is only used by lists and will have the same value as num_holdings.
		 (Also currently it has the same values as popularity)-->

	</fields>
	<uniqueKey>id</uniqueKey>
	<!-- Field to use to determine and enforce document uniqueness.
		 Unless this field is marked with required="false", it will be a required field
	  -->
	<!-- uniqueKey is required for MoreLikeThis handlers-->

	<!-- CopyFields for Faceting on Text -->
<!--	<copyField source="title_full" dest="title_fullStr"/>-->
	<copyField source="author" dest="authorStr"/>
	<copyField source="author" dest="author_exact"/>
	<copyField source="author" dest="author_left"/>
<!--	<copyField source="auth_author" dest="auth_authorStr"/>-->
<!--	<copyField source="author2" dest="author2Str"/>-->
<!--	<copyField source="auth_author2" dest="auth_author2Str"/>-->

	<!-- CopyFields for Proper (Unstemmed) searching -->
	<copyField source="title" dest="title_proper"/>
	<copyField source="title" dest="title_exact"/>
	<copyField source="title" dest="title_left"/>
	<copyField source="keywords" dest="keywords_proper"/>
	<copyField source="table_of_contents" dest="table_of_contents_proper"/>
	<copyField source="series" dest="series_proper"/>
	<copyField source="topic" dest="topic_proper"/>
	<copyField source="subject_facet" dest="subject"/>
	<copyField source="subject_facet" dest="subject_proper"/>
	<copyField source="geographic" dest="geographic_proper"/>
	<copyField source="era" dest="era_proper"/>
	<copyField source="genre" dest="genre_proper"/>
	<copyField source="local_callnumber_*" dest="local_callnumber_exact_*"/>
	<copyField source="local_callnumber_*" dest="local_callnumber_left_*"/>
</schema>
