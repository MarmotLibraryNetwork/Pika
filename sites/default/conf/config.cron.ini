# Configures the processes that cron will run when it is invoked with
# additional information about the frequency that it is invoked.
# The ini file should have a Processes section with the name of each process to run
#
# Processes should have the format:
#  - Process Name = Process Handler Class
#
# Each process will also have a section based on the Process Name.
# the section should contain the following keys at a minimum
# - description = A brief description of what the process does
# - frequencyHours = the frequency with which the process should be run in hours, or 0 if it should be run each time cron runs,
# or -1 to never run except when specified from the command line.
#
# General settings can also be defined that will be sent to all processes.
# these can include database connection information, solr settings, etc.

[Processes]
; Common Processes that are on by default
DatabaseCleanup = org.vufind.DatabaseCleanup
UpdateReadingHistory = org.vufind.UpdateReadingHistory
BookcoverCleanup = org.vufind.BookcoverCleanup

; All other processes should be off by default

; Common Processes
MaterialsRequest = org.vufind.MaterialsRequest
ReindexLists = org.vufind.ReindexLists

; MARC
ValidateMarcExport = org.vufind.ValidateMarcExport
SplitMarcExport = org.vufind.SplitMarcExport
MergeMarcUpdatesAndDeletes = org.vufind.MergeMarcUpdatesAndDeletes

; Sierra Libraries
ExportSierraData = org.innovative.ExportSierraData
SierraReports = org.innovative.SierraReports
OfflineCirculation = org.innovative.OfflineCirculation

; Horizon Libraries
MergeHorizonUsers = org.vufind.MergeHorizonUsers

; Carl-X libraries
CarlXMigration = org.nashville.CarlXMigration

; Marmot
DPLAFeed = org.marmot.DPLAFeed
ImportSteamboatGenealogy = org.marmot.ImportSteamboatGenealogy
GenealogyCleanup = org.marmot.GenealogyCleanup


;;;;;
; Common Processes that are on by default
;;;;;
[DatabaseCleanup]
;description = Does cleanup of the database to remove records that are no longer needed
frequencyHours = 24

[UpdateReadingHistory]
;description = Updates reading History for the patron based on what is currently checked out.  Only for use with Horizon
frequencyHours = 24

[BookcoverCleanup]
;description = Cleans up any book covers that are out of date (more than 2 weeks old).
frequencyHours = 1


;;;;;
; Common Processes
;;;;;
[MaterialsRequest]
;description = Handles processing background tasks for Materials Requests including sending emails to patrons and generating holds
frequencyHours = -1
;libraryName = Anythink Libraries
;circulationUrl = http://www.anythinklibraries.org
;circulationPhone = 555-5555
;circulationEmail = circulation@anythinklibraries.org

[ReindexLists]
;description = Reindexes public lists so they appear in the search results.  Only needs to be run if you are moving lists between systems.
frequencyHours = -1
baseSolrUrl = http://localhost:8080
reindexBiblio = true
reindexBiblio2 = true


;;;;;
; MARC
;;;;;
[ValidateMarcExport]
;description = Validates the MARC exports for a given system so we can determine if it is safe to run or not.
frequencyHours = -1

[SplitMarcExport]
;description = Splits the MARC export into separate files based on location code
frequencyHours = -1
;splitMarcPath        = /data/vufind-plus/marmot.test/split_marc
;split_1_filename = sd51.mrc
;split_1_locations = mv.*
;split_2_filename = cmu.mrc
;split_2_locations = ms.*|mdlm|mdlo|mdla|mdlgd|cu.*
;split_3_filename = adams.mrc
;split_3_locations = as.*
;split_4_filename = fortlewis.mrc
;split_4_locations = fl.*
;#Gold rush export
;split_5_filename = ccu_goldrush.marc
;split_5_locations = cccd|ccbk|ccvid|cceb|ccdis|ccmlc|ccmlv|ccmlb
;#Gold rush export
;split_6_filename = western_goldrush.marc
;split_6_locations = (wsst|wsrf|wsww|wspa).*
;#Gold rush export
;split_7_filename = fortlewis_goldrush.marc
;split_7_locations = flg.*|flc.*|flr.*|flm.*|flp.*
;#Gold rush export
;split_8_filename = cmu_goldrush.marc
;split_8_locations = ms.*|cu.*
;#Adams State Monographs
;split_9_filename = adams_monographs.marc
;split_9_locations = as|asar|asco|ascp|asea|asgv|asju|aslw|asnb|asnj|asno|asov|asre|asrf
;#Aspen Schools
;split_10_filename = aspen_elem.mrc
;split_10_locations = adel.*
;#Aspen Schools
;split_11_filename = aspen_middle.mrc
;split_11_locations = admi.*

[MergeMarcUpdatesAndDeletes]
;description = Merges full marc export with update and delete files provided as deltas
frequencyHours = -1

;;;;;
; Sierra Libraries
;;;;;
[ExportSierraData]
;description = Exports Sierra Data that is not needed for continuous indexing
frequencyHours = -1

[SierraReports]
;description = Creates reports using Sierra DNA to extract data from the database.
frequencyHours = -1
librariesToCreateReportsFor =

[OfflineCirculation]
;description = Processes holds, checkouts, and check-ins via Sierra Circa that were done when the Pika was in offline mode.
frequencyHours = -1

;;;;;
; Horizon Libraries
;;;;;
[MergeHorizonUsers]
;description = Merge Horizon users that are in the database twice once with Horizon User Id and once with the barcode
frequencyHours = -1

;;;;;
; Carl-X libraries
;;;;;
[CarlXMigration]
frequencyHours = -1
lssExportLocation = /data/pika/school.library.nashville.org/marc/schoolsextract.mrc
carlxExportLocation = /data/pika/nashville.production/marc/fullExport.mrc
deleteMissingUsers = false

;;;;;
; Marmot
;;;;;
[DPLAFeed]
;description = Compiles entries of DPLA Feed from the Archive API into a single file of JSON dpla.json that is stored in the base web directory
frequencyHours = -1
;pageSize = 75

[ImportSteamboatGenealogy]
;description = Import records from Steamboat Springs Genealogy Society
frequencyHours = -1
;steamboatFile = /home/mnoble/CleanLoadSteamboatCemetery06052012.csv
;ruralFile = /home/mnoble/CleanLoadRuralRouttCemetery06052012.csv

[GenealogyCleanup]
;description = TODO
frequencyHours = -1
deleteDuplicates = false
reindex = true
genealogyIndex = http://localhost:8080/solr/genealogy

